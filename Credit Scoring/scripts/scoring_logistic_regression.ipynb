{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce189e70-8e3d-4d43-bf46-31c16977000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5ae66c-0288-47da-8336-32d3f4b9367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Move up one level from 'scripts/' and access 'data/'\n",
    "file_path = os.path.join(\"..\", \"data\", \"AER_credit_card_data.csv\")\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee806ba-8d2c-4f27-a11f-45b744828bd1",
   "metadata": {},
   "source": [
    "### Why logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee7941-e555-4be2-8086-8f86479250c9",
   "metadata": {},
   "source": [
    "Used for binary classification (e.g., default vs. no default). \n",
    "\n",
    "Predicts a class (0 or 1) based on a probability threshold (e.g., 0.5).\n",
    "\n",
    "Can interpret feature importance of the coefficients supplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98fdd2f4-99f6-42f8-a979-eb44b440d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4302a5d-dac1-4d15-aa37-415fc170d84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01eca3d9-8596-4936-98f6-9d827879ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           age    income     share  expenditure  owner  selfemp  dependents  \\\n",
      "598   1.045537  0.607896 -0.260383    -0.093756      1        0    0.777563   \n",
      "1213 -0.493522  1.273808 -0.417862    -0.197316      1        0    1.569386   \n",
      "209  -0.237011  0.264575 -0.383169    -0.311005      0        0   -0.806084   \n",
      "538   0.408400 -1.016606 -0.714854    -0.700058      1        0    1.569386   \n",
      "140   0.333930 -0.218889  0.456763     0.367486      0        0    0.777563   \n",
      "\n",
      "        months  majorcards    active  negative_reports  \n",
      "598   0.825741           1  0.500268                 0  \n",
      "1213 -0.562893           1 -1.109315                 0  \n",
      "209  -0.442142           0 -0.948357                 0  \n",
      "538   0.976679           0  0.178351                 0  \n",
      "140  -0.593081           1 -0.143566                 0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert categorical values ('yes' → 1, 'no' → 0)\n",
    "df['card'] = df['card'].map({'yes': 1, 'no': 0})\n",
    "df['owner'] = df['owner'].map({'yes': 1, 'no': 0})\n",
    "df['selfemp'] = df['selfemp'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Create the 'negative_reports' column\n",
    "df['negative_reports'] = np.where(df['reports'] >= 1, 1, 0)\n",
    "\n",
    "# Drop the original 'reports' column\n",
    "df = df.drop(columns=['reports'])\n",
    "\n",
    "\n",
    "# Identify binary categorical variables\n",
    "binary_columns = ['owner', 'selfemp', 'majorcards', 'negative_reports']\n",
    "\n",
    "# Identify continuous variables (all others)\n",
    "continuous_columns = [col for col in X.columns if col not in binary_columns]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale only continuous variables\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[continuous_columns] = scaler.fit_transform(X_train[continuous_columns])\n",
    "X_test_scaled[continuous_columns] = scaler.transform(X_test[continuous_columns])\n",
    "\n",
    "# Convert to DataFrame for easier interpretation\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "\n",
    "print(X_train_scaled_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a177b8a9-6931-403e-8977-f29a7e6978f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.95\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90        62\n",
      "           1       0.97      0.98      0.97       202\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.93      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ba566d-662d-435b-bfae-38a1f4f92520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card\n",
      "1    821\n",
      "0    234\n",
      "Name: count, dtype: int64\n",
      "card\n",
      "1    202\n",
      "0     62\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f31e43ee-8383-4a1b-987c-1458f13e863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Coefficient\n",
      "2              share     5.937128\n",
      "3        expenditure     5.417918\n",
      "8         majorcards     0.528927\n",
      "9             active     0.478437\n",
      "4              owner     0.298819\n",
      "1             income     0.091953\n",
      "0                age     0.087303\n",
      "5            selfemp     0.071127\n",
      "7             months    -0.039601\n",
      "6         dependents    -0.170967\n",
      "10  negative_reports    -2.250995\n"
     ]
    }
   ],
   "source": [
    "# Get model coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Coefficient\": model.coef_[0]\n",
    "}).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "# Display feature importance\n",
    "print(coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9c350-d71f-4e40-bced-4ec51d8dc1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
